#version 450
layout(local_size_x = 16, local_size_y = 16) in;

struct Triangle {
    vec3 v0, v1, v2;
    vec3 normal;
    uint materialID;
};

struct Material {
    vec3 albedo;
    float metallic;
    float roughness;
    float ambientOcclusion;
    float padding1; // pad to 16 bytes
    float emission;
};

layout(set = 0, binding = 0, rgba32f) uniform image2D outputImage;

layout(std140, set = 1, binding = 0) buffer Triangles { Triangle tris[]; };

layout(std140, set = 1, binding = 1) uniform MaterialBlock {
    Material materials[16];
};

// 使用 UBO 传递摄像机和帧信息
layout(std140, set = 1, binding = 2) uniform CameraData {
    mat4 invViewProj; // 逆投影矩阵
    vec3 cameraPos;   // 摄像机位置
    int frame;        // 当前帧编号
};

#define MAX_BOUNCES 4
#define PI 3.14159265359

// === 随机函数 ===
uint seed;
float rand() {
    seed ^= seed << 13;
    seed ^= seed >> 17;
    seed ^= seed << 5;
    return float(seed & 0x00FFFFFF) / float(0x01000000);
}

// === 相交函数（简单实现） ===
bool intersectRayTriangle(vec3 orig, vec3 dir, out int hitIndex, out float t, out vec3 normal) {
    t = 1e20; // 初始化为一个很大的值，表示当前没有找到交点
    hitIndex = -1; // 初始化为未命中
    normal = vec3(0.0); // 初始化法线

    for (int i = 0; i < tris.length(); ++i) {
        Triangle tri = tris[i];

        // 计算三角形的两条边
        vec3 edge1 = tri.v1 - tri.v0;
        vec3 edge2 = tri.v2 - tri.v0;

        // 计算光线方向与 edge2 的叉积
        vec3 pvec = cross(dir, edge2);

        // 计算行列式，用于判断光线是否平行于三角形
        float det = dot(edge1, pvec);
        if (abs(det) < 0.0001) continue; // 行列式接近 0，光线与三角形平行，跳过

        float invDet = 1.0 / det;

        // 计算从三角形顶点到光线起点的向量
        vec3 tvec = orig - tri.v0;

        // 计算重心坐标 u
        float u = dot(tvec, pvec) * invDet;
        if (u < 0.0 || u > 1.0) continue; // u 超出范围，跳过

        // 计算 qvec，用于计算重心坐标 v
        vec3 qvec = cross(tvec, edge1);

        // 计算重心坐标 v
        float v = dot(dir, qvec) * invDet;
        if (v < 0.0 || u + v > 1.0) continue; // v 超出范围，跳过

        // 计算交点距离 t
        float tmpT = dot(edge2, qvec) * invDet;
        if (tmpT > 0.001 && tmpT < t) { // 找到更近的交点
            t = tmpT;
            hitIndex = i;
            normal = normalize(tri.normal); // 确保法线归一化

            // // 确保法线朝向光线方向
            // if (dot(normal, dir) > 0.0) {
            //     normal = -normal;
            // }
        }
    }

    return hitIndex != -1; // 如果命中，返回 true；否则返回 false
}

// === 采样单位半球 ===
vec3 sampleHemisphere(vec3 normal) {
    float u1 = rand();
    float u2 = rand();
    float r = sqrt(u1);
    float theta = 2.0 * PI * u2;

    vec3 up = abs(normal.y) < 0.999 ? vec3(0.0, 1.0, 0.0) : vec3(1.0, 0.0, 0.0);
    vec3 tangent = normalize(cross(normal, up));
    vec3 bitangent = cross(normal, tangent);

    return normalize(
        r * cos(theta) * tangent +
        r * sin(theta) * bitangent +
        sqrt(1.0 - u1) * normal
    );
}

// === 主追踪函数 ===
vec3 traceRay(vec3 origin, vec3 dir) {
    vec3 throughput = vec3(1.0);
    vec3 radiance = vec3(0.0);

    for (int bounce = 0; bounce < MAX_BOUNCES; ++bounce) {
        int hitIndex;
        float t;
        vec3 normal;
        if (!intersectRayTriangle(origin, dir, hitIndex, t, normal)) {
            // return vec3(1,0,1); // 没有命中，返回背景色
            break;
        }

        Triangle tri = tris[hitIndex];
        Material mat = materials[tri.materialID];
    
        origin += dir * t + normal * 0.001; // 防止自相交
        dir = sampleHemisphere(normal);

        radiance += throughput * mat.emission;
        throughput *= mat.albedo;
    }

    return radiance;
}

// === Main Entry ===
void main() {
    ivec2 pix = ivec2(gl_GlobalInvocationID.xy);
    vec2 uv = (vec2(pix) + vec2(rand(), rand())) / imageSize(outputImage) * 2.0 - 1.0;
    
    vec4 target = invViewProj * vec4(uv, 0.0, 1.0);
    vec3 dir = normalize(target.xyz / target.w - cameraPos);

    seed = uint(pix.x + pix.y * 512 + frame * 1337);

    vec3 color = traceRay(cameraPos, dir);

    vec4 prevColor = imageLoad(outputImage, pix);

    // 如果是第一帧，直接写入；否则做累计平均
    float alpha = 0.05; // 衰减速度，可以调试
    vec3 blended = (frame == 0)
        ? color
        : mix(prevColor.rgb, color, 1.0 / float(frame + 1));
    // vec3 blended = (frame == 0)
    //     ? color
    //     : mix(prevColor.rgb, color, alpha);
    // vec3 toneMapped = blended / (blended + vec3(1.0));
    imageStore(outputImage, pix, vec4(blended, 1.0));
}
